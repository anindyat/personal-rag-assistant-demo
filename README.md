# personal-rag-assistant-demo
Personal RAG Assistant
This project started as an experiment in Agentic AI â€” building an autonomous, context-aware assistant that could reason, retrieve, and respond based on my own data.

I didnâ€™t spend a dollar on hosting or APIs â€” everything ran locally.

Hereâ€™s what I put together:

ğŸ§¾ Data Foundation:
I began with a small family profile text file, describing who I am, my daughter, and basic family details â€” just enough context for grounding.

ğŸ“§ Email Integration:
I connected securely to my personal email using an access key from my provider, limiting it to recent emails and attachments to keep the dataset lightweight.

ğŸ”¢ Vectorization:
Using OpenAI Embeddings and an AutoEncoder-based open-source LLM, I vectorized both the family and email data, and stored them in a local Chroma vector datastore.

ğŸ§© RAG Construction:
With LangChain, I stitched together a Retrieval-Augmented Generation (RAG) pipeline â€” combining local document retrieval with generative reasoning.

ğŸ™ï¸ Voice Input:
The Gradio chat interface accepts audio input.
The speech is first transcribed into text using the Whisper-1 model.

ğŸ’¬ Reasoning and Response:
The transcribed text is sent to an open-source LLM, augmented by RAG retrievals from Chroma â€” ensuring that responses are both contextually grounded and cost-efficient.

ğŸ”Š Voice Output:
Finally, the text response is converted back into speech using gpt-4o-mini-tts, completing a natural, conversational loop.

ğŸ”’ Privacy by Design

For security reasons, none of the data â€” not even embeddings â€” left my local environment.
All retrieval, inference, and storage were done entirely on my machine.
Itâ€™s not production-grade, but itâ€™s good enough for personal use â€” and safe enough for private context.
